\begin{center}
	\textbf{\textbf{\fontsize{16pt}{24pt}\selectfont Abstract}}
\end{center}
\par Conditional adversarial networks are being investigated as a general-purpose solution to image-to-image translation difficulties. These networks not only learn the mapping from input to output image, but also the loss function that will be used to train the mapping. This allows the same generic method to be applied to problems that would normally require quite different loss formulas. We show that, among other things, this method may be used to synthesise photographs from label maps, reconstruct objects from edge maps, and colourize images. Its broad applicability and ease of adoption without the need for parameter tweaking are further demonstrated. It's used to create effective losses. To put it another way, we still need to tell CNN what we want it to downplay.This is due to the fact that Euclidean distance is reduced by averaging all feasible outputs, resulting in blurring. Developing loss functions that drive the CNN to accomplish what we truly want — e.g., output clear, realistic images – is a work in progress that typically necessitates specialist knowledge. It would be ideal if we could instead give merely a high-level aim, such as "make the output indistinguishable from reality," and then the loss function appropriate for achieving this goal would be learned automatically. Fortunately, the recently suggested Generative Adversarial Networks achieve precisely that (GANs). GANs learn a loss that attempts to classify whether the output image is real or false while also training a generative model to reduce the loss. Blurry photos will not be accepted because they can be applied to a multitude of tasks that traditionally would require very different kinds of loss functions.



\\ \textbf{\textit{Keywords : }} GAN Model, CNN,RNN,LSTM, Deep Learning
%First paragraph \par
%Second Paragraph \par
%Third Paragraphy \par

